{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number Recognition Using MNIST Dataset\n",
    "\n",
    "According to [Wikipedia](https://en.wikipedia.org/wiki/MNIST_database), the MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. The database is widely used for training and testing in the field of machine learning. It was created by \"re-mixing\" the samples from NIST's original datasets. Furthermore, the black and white images from NIST were normalized to fit into a 28x28 pixel bounding box and anti-aliased, which introduced grayscale levels.\n",
    "\n",
    "![](MnistExamplesModified.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "         MaxPool2d-2           [-1, 32, 14, 14]               0\n",
      "            Conv2d-3           [-1, 64, 14, 14]          18,496\n",
      "         MaxPool2d-4             [-1, 64, 7, 7]               0\n",
      "            Linear-5                  [-1, 128]         401,536\n",
      "            Linear-6                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 421,642\n",
      "Trainable params: 421,642\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.36\n",
      "Params size (MB): 1.61\n",
      "Estimated Total Size (MB): 1.97\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, Iteration 100, Loss 0.532\n",
      "Epoch 1, Iteration 200, Loss 0.157\n",
      "Epoch 1, Iteration 300, Loss 0.100\n",
      "Epoch 1, Iteration 400, Loss 0.085\n",
      "Epoch 1, Iteration 500, Loss 0.084\n",
      "Epoch 1, Iteration 600, Loss 0.058\n",
      "Epoch 1, Iteration 700, Loss 0.067\n",
      "Epoch 1, Iteration 800, Loss 0.055\n",
      "Epoch 1, Iteration 900, Loss 0.056\n",
      "Epoch 2, Iteration 100, Loss 0.036\n",
      "Epoch 2, Iteration 200, Loss 0.042\n",
      "Epoch 2, Iteration 300, Loss 0.044\n",
      "Epoch 2, Iteration 400, Loss 0.045\n",
      "Epoch 2, Iteration 500, Loss 0.040\n",
      "Epoch 2, Iteration 600, Loss 0.043\n",
      "Epoch 2, Iteration 700, Loss 0.035\n",
      "Epoch 2, Iteration 800, Loss 0.040\n",
      "Epoch 2, Iteration 900, Loss 0.041\n",
      "Epoch 3, Iteration 100, Loss 0.022\n",
      "Epoch 3, Iteration 200, Loss 0.029\n",
      "Epoch 3, Iteration 300, Loss 0.027\n",
      "Epoch 3, Iteration 400, Loss 0.031\n",
      "Epoch 3, Iteration 500, Loss 0.028\n",
      "Epoch 3, Iteration 600, Loss 0.031\n",
      "Epoch 3, Iteration 700, Loss 0.020\n",
      "Epoch 3, Iteration 800, Loss 0.025\n",
      "Epoch 3, Iteration 900, Loss 0.027\n",
      "Epoch 4, Iteration 100, Loss 0.014\n",
      "Epoch 4, Iteration 200, Loss 0.019\n",
      "Epoch 4, Iteration 300, Loss 0.016\n",
      "Epoch 4, Iteration 400, Loss 0.018\n",
      "Epoch 4, Iteration 500, Loss 0.019\n",
      "Epoch 4, Iteration 600, Loss 0.022\n",
      "Epoch 4, Iteration 700, Loss 0.026\n",
      "Epoch 4, Iteration 800, Loss 0.019\n",
      "Epoch 4, Iteration 900, Loss 0.016\n",
      "Epoch 5, Iteration 100, Loss 0.011\n",
      "Epoch 5, Iteration 200, Loss 0.008\n",
      "Epoch 5, Iteration 300, Loss 0.012\n",
      "Epoch 5, Iteration 400, Loss 0.017\n",
      "Epoch 5, Iteration 500, Loss 0.016\n",
      "Epoch 5, Iteration 600, Loss 0.012\n",
      "Epoch 5, Iteration 700, Loss 0.015\n",
      "Epoch 5, Iteration 800, Loss 0.017\n",
      "Epoch 5, Iteration 900, Loss 0.018\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 99.06%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "# Define neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# Instantiate the neural network\n",
    "net = Net()\n",
    "\n",
    "# Print the summary of the neural network\n",
    "summary(net, input_size=(1, 28, 28))\n",
    "\n",
    "# Transform and load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Train the neural network\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 100 == 99:\n",
    "            print(f'Epoch {epoch + 1}, Iteration {i + 1}, Loss {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Test the neural network\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\n",
    "\n",
    "# Save the trained model\n",
    "#torch.save(net.state_dict(), 'mnist_cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
